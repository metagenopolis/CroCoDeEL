from multiprocessing import Pool
from functools import partial
from itertools import product
import logging
from time import perf_counter
from typing import Final, Any
import numpy as np
import pandas as pd
import tqdm
from sklearn.linear_model import RANSACRegressor, LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.neighbors import NearestNeighbors
from scipy.stats import spearmanr
from crocodeel import ab_table_utils
from crocodeel.conta_event import ContaminationEvent, ContaminationEventIO
from crocodeel.rf_model import RandomForestModel


def run_search_conta(args: dict[str,Any]):
    # Load species abundance table if necessary
    if "species_ab_table" in args:
        species_ab_table = args["species_ab_table"]
    else:
        species_ab_table = ab_table_utils.read(args["species_ab_table_fh"])
        args["species_ab_table_fh"].close()
        species_ab_table = ab_table_utils.normalize(species_ab_table)

    start = perf_counter()
    logging.info("Search for contaminations started")
    conta_events = ContaminationSearcherDriver(
        species_ab_table,
        nproc=args['nproc']
    ).search_contamination()
    logging.info("Search completed in %.1f seconds", np.round(perf_counter() - start, 1))

    contaminated_samples = {conta_event.target for conta_event in conta_events}
    logging.info("%d contamination events detected", len(conta_events))
    logging.info("%d/%d samples contaminated", len(contaminated_samples), species_ab_table.shape[1])

    conta_events.sort(key=lambda e: e.rate, reverse=True)
    ContaminationEventIO.write_tsv(conta_events, args['conta_events_fh'])
    logging.info(
        "Contamination events sorted by decreasing contamination rate saved in %s",
        args["conta_events_fh"].name,
    )
    if args["conta_events_fh"].mode == 'w':
        args["conta_events_fh"].close()

    logging.warning("Contamination events may be false positives, "
                    "especially when dealing with samples with similar species abundance profiles "
                    "(longitudinal data, animals raised together)")
    logging.warning("Check each reported contamination event by inspecting "
                    "scatterplots generated by the plot_conta subcommand")

class UnitSlopeRegression(LinearRegression):
    def fit(self, X, y, sample_weight=None):
        self.coeffs = (1, np.mean(y) - np.mean(X))
        return super().fit(X, y)

    def predict(self, X):
        y_hat = X * self.coeffs[0] + self.coeffs[1]
        return y_hat

    def score(self, X, y, sample_weight=None):
        return mean_squared_error(y, self.predict(X))


class ContaminationSearcherWorker:
    UPPER_LEFT_TRIANGLE_LIMIT = 2
    RESIDUAL_THRESHOLD = 0.2
    NUMBER_NEAREST_NEIGHBORS = 5
    NUMBER_FARTHEST_NEIGHBORS = 5
    NUMBER_SPECIFIC_SPECIES_TO_CONSIDER = 10
    PROBABILITY_CUTOFF = 0.5

    def __init__(self, species_ab_table, rf_classifier):
        self.species_ab_table = species_ab_table
        self.rf_classifier = rf_classifier

    def get_mean_abundance_of_most_abundant_species_specific_to_source_sample(
        self,
        specific_species_to_source_sample,
        intercept_specific_species_to_source_sample,
        number_of_species=NUMBER_SPECIFIC_SPECIES_TO_CONSIDER,
    ):
        """"""
        specific_species_to_source_sample_sorted = specific_species_to_source_sample[
            specific_species_to_source_sample[:, 1].argsort()[::-1]
        ]
        if specific_species_to_source_sample_sorted.shape[0] == 0:
            return intercept_specific_species_to_source_sample
        return (specific_species_to_source_sample_sorted[:number_of_species, 1]).mean()

    def get_distance_between_mean_abundance_of_specific_species_and_contamination_line(
        self,
        specific_species_to_source_sample,
        intercept_specific_species_to_source_sample,
        number_of_species=NUMBER_SPECIFIC_SPECIES_TO_CONSIDER,
    ):
        mean_abundance_of_most_abundant_species_specific_to_source_sample = (
            self.get_mean_abundance_of_most_abundant_species_specific_to_source_sample(
                specific_species_to_source_sample, intercept_specific_species_to_source_sample, number_of_species
            )
        )
        return np.abs(
            mean_abundance_of_most_abundant_species_specific_to_source_sample
            - intercept_specific_species_to_source_sample
        )

    def get_distance_between_mean_abundance_of_specific_species_and_contamination_line2(
        self,
        specific_species_to_source_sample,
        intercept_specific_species_to_source_sample,
        species_potentially_in_contamination_line_inliers,
        number_of_species=10,
    ):
        mean_abundance_of_most_abundant_species_specific_to_source_sample = (
            self.get_mean_abundance_of_most_abundant_species_specific_to_source_sample(
                specific_species_to_source_sample, intercept_specific_species_to_source_sample, number_of_species
            )
        )
        if (
            mean_abundance_of_most_abundant_species_specific_to_source_sample
            == intercept_specific_species_to_source_sample
        ):
            return 0
        sorted_points = species_potentially_in_contamination_line_inliers[
            species_potentially_in_contamination_line_inliers[:, 1].argsort()
        ]
        if int(0.1 * len(species_potentially_in_contamination_line_inliers)) > 1:
            num_points_to_select = int(0.1 * len(species_potentially_in_contamination_line_inliers))
        else:
            num_points_to_select = 1
        selected_points = sorted_points[:num_points_to_select]
        return np.abs(
            mean_abundance_of_most_abundant_species_specific_to_source_sample - np.mean(selected_points[:, 1])
        )

    def get_mean_distance_to_nearest_neighbors(self, data, number_of_neighbors=NUMBER_NEAREST_NEIGHBORS):
        """"""
        if data.shape[0] < number_of_neighbors:
            number_of_neighbors = data.shape[0]
        neighbors_model = NearestNeighbors(n_neighbors=number_of_neighbors)
        neighbors_model.fit(data)
        nearest_neighbors_distances, _ = neighbors_model.kneighbors(data)
        return nearest_neighbors_distances.mean().mean()

    def get_mean_distance_to_farthest_neighbors(self, data, number_of_neighbors=NUMBER_FARTHEST_NEIGHBORS):
        """"""
        neighbors_model = NearestNeighbors(n_neighbors=data.shape[0])
        neighbors_model.fit(data)
        distances, _ = neighbors_model.kneighbors(data)
        sorted_distances = np.sort(distances)
        farthest_neighbors_distances = sorted_distances[:, -number_of_neighbors:]
        return farthest_neighbors_distances.mean().mean()

    def compute_features(self, intercept, species_potentially_in_contamination_line_inliers, not_filtered_data):
        # Specific species to the source sample
        specific_species_to_source_sample = not_filtered_data[
            (not_filtered_data[:, 0] == -np.inf) & (not_filtered_data[:, 1] != -np.inf), :
        ]

        # Shared species between source and target samples
        shared_species = not_filtered_data[(not_filtered_data[:, 0] != -np.inf) & (not_filtered_data[:, 1] != -np.inf)]
        number_of_shared_species = shared_species.shape[0]

        #
        number_of_species_in_contamination_line = species_potentially_in_contamination_line_inliers.shape[0]
        ratio_species_in_contamination_line_to_shared_species = (
            number_of_species_in_contamination_line / number_of_shared_species
        )
        number_of_species_above_line = np.sum(shared_species[:, 1] > shared_species[:, 0] + intercept + 0.2)
        ratio_species_above_line_to_shared_species = number_of_species_above_line / number_of_shared_species

        #
        mean_distance_to_nearest_neighbors = self.get_mean_distance_to_nearest_neighbors(
            species_potentially_in_contamination_line_inliers
        )
        mean_distance_to_farthest_neighbors = self.get_mean_distance_to_farthest_neighbors(
            species_potentially_in_contamination_line_inliers
        )

        #
        pseudo_zero = np.min(not_filtered_data[not_filtered_data[:, 0] != -np.inf, 0]) - 1
        intercept_specific_species_to_source_sample = pseudo_zero + intercept
        distance_between_mean_abundance_of_specific_species_and_contamination_line = (
            self.get_distance_between_mean_abundance_of_specific_species_and_contamination_line(
                specific_species_to_source_sample, intercept_specific_species_to_source_sample
            )
        )
        distance_between_mean_abundance_of_specific_species_and_contamination_line2 = (
            self.get_distance_between_mean_abundance_of_specific_species_and_contamination_line2(
                specific_species_to_source_sample,
                intercept_specific_species_to_source_sample,
                species_potentially_in_contamination_line_inliers,
            )
        )

        #
        correlation_spearman_all_species = spearmanr(not_filtered_data[:, 0], not_filtered_data[:, 1])[0]

        #
        distances = np.abs(
            species_potentially_in_contamination_line_inliers[:, 1]
            - species_potentially_in_contamination_line_inliers[:, 0]
            - intercept
        ) / np.sqrt(2)
        mean_distance_to_the_contamination_line = distances.mean()

        return (
            ratio_species_in_contamination_line_to_shared_species,
            ratio_species_above_line_to_shared_species,
            number_of_species_in_contamination_line,
            number_of_species_above_line,
            correlation_spearman_all_species,
            mean_distance_to_the_contamination_line,
            mean_distance_to_nearest_neighbors,
            mean_distance_to_farthest_neighbors,
            distance_between_mean_abundance_of_specific_species_and_contamination_line,
            distance_between_mean_abundance_of_specific_species_and_contamination_line2,
        )

    def get_coefficients_of_potential_contamination_line(self, species_potentially_in_contamination_line):
        """ """
        ransac = RANSACRegressor(
            estimator=UnitSlopeRegression(), random_state=42, residual_threshold=self.RESIDUAL_THRESHOLD
        )
        ransac.fit(
            species_potentially_in_contamination_line[:, [0]],
            species_potentially_in_contamination_line[:, [1]],
        )

        species_inliers = ransac.inlier_mask_
        intercept = ransac.estimator_.coeffs[1]

        return species_inliers, intercept

    def select_species_potentially_in_contamination_line(self, source_sample_name, target_sample_name):
        """Return"""
        # Select all species or only those in upper triangle
        not_filtered_data = self.species_ab_table[[target_sample_name, source_sample_name]]
        shared_species_upper_triangle = (
            not_filtered_data[source_sample_name] >= not_filtered_data[target_sample_name]
        ) & (not_filtered_data[target_sample_name] != -np.inf)

        # convert to numpy array
        shared_species_upper_triangle = not_filtered_data[shared_species_upper_triangle]
        shared_species_upper_triangle_indexes = shared_species_upper_triangle.index.values
        not_filtered_data = not_filtered_data.to_numpy()
        shared_species_upper_triangle = shared_species_upper_triangle.to_numpy()

        # search species potentially in the contamination line
        species_potentially_in_contamination_line = []
        for species_id, point in enumerate(shared_species_upper_triangle):
            number_of_points_in_upper_left_triangle = np.sum(
                (shared_species_upper_triangle[:, 0] <= point[0]) & (shared_species_upper_triangle[:, 1] >= point[1])
            )
            number_of_points_in_upper_left_triangle -= 1
            if number_of_points_in_upper_left_triangle <= self.UPPER_LEFT_TRIANGLE_LIMIT:
                species_potentially_in_contamination_line.append(species_id)
        species_potentially_in_contamination_line_indexes = shared_species_upper_triangle_indexes[
            species_potentially_in_contamination_line
        ]
        species_potentially_in_contamination_line = shared_species_upper_triangle[
            species_potentially_in_contamination_line
        ]

        return (
            not_filtered_data,
            species_potentially_in_contamination_line,
            species_potentially_in_contamination_line_indexes,
        )

    def classify_sample_pair(self, sample_pair):
        source, target = sample_pair

        if source == target:
            return ContaminationEvent(source, target)

        # Search a potential contamination line
        (
            not_filtered_data,
            species_potentially_in_contamination_line,
            species_potentially_in_contamination_line_indexes,
        ) = self.select_species_potentially_in_contamination_line(source, target)

        while True:
            # Not enough species in the potential contamination line
            # no contamination found, exit loop
            if species_potentially_in_contamination_line.shape[0] <= 5:
                return ContaminationEvent(source, target)

            # Run RANSAC to estimate the intercept of the potential contamination line
            # and get inlier and outlier species
            species_inliers, intercept = self.get_coefficients_of_potential_contamination_line(
                species_potentially_in_contamination_line
            )

            # Not enough inlier species in the potential contamination line
            # no contamination found, exit loop
            if np.sum(species_inliers) <= 5:
                return ContaminationEvent(source, target)

            species_outliers = np.logical_not(species_inliers)
            species_inliers_indexes = species_potentially_in_contamination_line_indexes[species_inliers]
            species_inliers = species_potentially_in_contamination_line[species_inliers]

            # Extract features describing the current sample pair and the potential contamination line
            features = self.compute_features(intercept, species_inliers, not_filtered_data)
            features = np.array([features])

            # Apply the random forest model with the extracted features
            contamination_probability = self.rf_classifier.predict_proba(features)[0, 1]

            # contamination found, exit loop
            if contamination_probability >= self.PROBABILITY_CUTOFF:
                contamination_rate = np.round(10 ** (-intercept), 4)
                return ContaminationEvent(
                    source,
                    target,
                    rate=contamination_rate,
                    probability=contamination_probability,
                    contamination_specific_species=species_inliers_indexes.tolist(),
                )

            # no contamination found with inliers
            # try with remaining outliers
            species_potentially_in_contamination_line = species_potentially_in_contamination_line[species_outliers]
            species_potentially_in_contamination_line_indexes = species_potentially_in_contamination_line_indexes[
                species_outliers
            ]


class ContaminationSearcherDriver:
    DEFAULT_CHUNKSIZE: Final[int] = 50

    def __init__(self, species_ab_table: pd.DataFrame, nproc: int):
        self.species_ab_table = species_ab_table
        self.nproc = nproc

    def search_contamination(self):
        all_samples = self.species_ab_table.columns
        all_sample_pairs = product(all_samples, repeat=2)
        num_sample_pairs = len(all_samples) ** 2

        rf_classifier = RandomForestModel.load()
        worker = ContaminationSearcherWorker(self.species_ab_table, rf_classifier)

        all_conta_events = []

        with Pool(processes=self.nproc) as pool:
            all_tasks = pool.imap_unordered(
                worker.classify_sample_pair, all_sample_pairs, chunksize=self.DEFAULT_CHUNKSIZE
            )
            pbar = partial(
                tqdm.tqdm,
                total=num_sample_pairs,
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} sample pairs inspected",
            )
            for conta_event in pbar(all_tasks):
                if conta_event.probability >= ContaminationSearcherWorker.PROBABILITY_CUTOFF:
                    all_conta_events.append(conta_event)

        return all_conta_events
