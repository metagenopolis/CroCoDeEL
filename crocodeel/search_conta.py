from multiprocessing import Pool
from functools import partial
from itertools import product
import logging
from pathlib import Path
from time import perf_counter
from typing import Final, Any, Optional, TextIO
import sys
import numpy as np
import pandas as pd
import tqdm
from crocodeel import ab_table_utils
from crocodeel.conta_event import ContaminationEvent, ContaminationEventIO
from crocodeel.rf_model import RandomForestModel
from crocodeel.common import (
    select_species_potentially_in_contamination_line,
    get_coefficients_of_potential_contamination_line,
    compute_features
)


def run_search_conta(args: dict[str,Any]):
    # Load species abundance table if necessary
    if "species_ab_table" in args:
        species_ab_table = args["species_ab_table"]
    else:
        species_ab_table = ab_table_utils.read(args["species_ab_table_fh"])
        args["species_ab_table_fh"].close()
        species_ab_table = ab_table_utils.normalize(species_ab_table)

    start = perf_counter()
    logging.info("Search for contaminations started")
    conta_events = ContaminationSearcherDriver(
        species_ab_table,
        nproc=args['nproc']
    ).search_contamination()
    logging.info("Search completed in %.1f seconds", np.round(perf_counter() - start, 1))

    _save_results(conta_events,  args['conta_events_fh'])

def run_search_conta_distrib(args: dict[str,Any]):
    species_ab_table = ab_table_utils.read(args["species_ab_table_fh"])
    args["species_ab_table_fh"].close()
    species_ab_table = ab_table_utils.normalize(species_ab_table)

    species_ab_table_2 = ab_table_utils.read(args["species_ab_table_fh_2"])
    args["species_ab_table_fh_2"].close()
    species_ab_table_2 = ab_table_utils.normalize(species_ab_table_2)

    if species_ab_table.shape[0] != species_ab_table_2.shape[0]:
        logging.error('Abundance tables do not have the same number of species (%d vs %d)',
                      species_ab_table.shape[0], species_ab_table_2.shape[0])
        sys.exit(1)

    if not species_ab_table.index.equals(species_ab_table_2.index):
        logging.error("Abundance tables do not have the same species names")
        sys.exit(1)

    start = perf_counter()
    logging.info("Search for contaminations started")
    conta_events = ContaminationSearcherDriver(
        species_ab_table,
        species_ab_table_2,
        nproc=args['nproc']
    ).search_contamination()
    logging.info("Search completed in %.1f seconds", np.round(perf_counter() - start, 1))

    _save_results(conta_events,  args['conta_events_fh'])

def _save_results(conta_events: list[ContaminationEvent], conta_events_fh: TextIO):
    contaminated_samples = {conta_event.target for conta_event in conta_events}
    logging.info("%d contamination events detected", len(conta_events))
    logging.info("%d samples contaminated", len(contaminated_samples))

    conta_events.sort(key=lambda e: e.rate, reverse=True)
    ContaminationEventIO.write_tsv(conta_events, conta_events_fh)
    logging.info(
        "Contamination events sorted by decreasing rate saved in %s",
        Path(conta_events_fh.name).resolve(),
    )
    if conta_events_fh.mode == 'w':
        conta_events_fh.close()

    logging.warning("Contamination events may be false positives, "
                    "especially when dealing with samples with similar species abundance profiles "
                    "(longitudinal data, animals raised together)")
    logging.warning("Check each reported contamination event by inspecting "
                    "scatterplots generated by the plot_conta subcommand")


class ContaminationSearcherWorker:
    PROBABILITY_CUTOFF: Final[float] = 0.5

    def __init__(self, species_ab_table, rf_classifier):
        self.species_ab_table = species_ab_table
        self.rf_classifier = rf_classifier

    def classify_sample_pair(self, sample_pair):
        source, target = sample_pair

        if source == target:
            return ContaminationEvent(source, target)

        # Search a potential contamination line
        (
            not_filtered_data,
            species_potentially_in_contamination_line,
            species_potentially_in_contamination_line_indexes,
        ) = select_species_potentially_in_contamination_line(self.species_ab_table, source, target)

        while True:
            # Not enough species in the potential contamination line
            # no contamination found, exit loop
            if species_potentially_in_contamination_line.shape[0] <= 5:
                return ContaminationEvent(source, target)

            # Run RANSAC to estimate the intercept of the potential contamination line
            # and get inlier and outlier species
            species_inliers, intercept = get_coefficients_of_potential_contamination_line(
                species_potentially_in_contamination_line
            )

            # Not enough inlier species in the potential contamination line
            # no contamination found, exit loop
            if np.sum(species_inliers) <= 5:
                return ContaminationEvent(source, target)

            species_outliers = np.logical_not(species_inliers)
            species_inliers_indexes = species_potentially_in_contamination_line_indexes[species_inliers]
            species_inliers = species_potentially_in_contamination_line[species_inliers]

            # Extract features describing the current sample pair and the potential contamination line
            features = compute_features(intercept, species_inliers, not_filtered_data)
            features = np.array([features])

            # Apply the random forest model with the extracted features
            contamination_probability = self.rf_classifier.predict_proba(features)[0, 1]

            # contamination found, exit loop
            if contamination_probability >= self.PROBABILITY_CUTOFF:
                contamination_rate = np.round(10 ** (-intercept), 4)
                return ContaminationEvent(
                    source,
                    target,
                    rate=contamination_rate,
                    probability=contamination_probability,
                    contamination_specific_species=species_inliers_indexes.tolist(),
                )

            # no contamination found with inliers
            # try with remaining outliers
            species_potentially_in_contamination_line = species_potentially_in_contamination_line[species_outliers]
            species_potentially_in_contamination_line_indexes = species_potentially_in_contamination_line_indexes[
                species_outliers
            ]


class ContaminationSearcherDriver:
    DEFAULT_CHUNKSIZE: Final[int] = 50

    def __init__(
        self, species_ab_table: pd.DataFrame, species_ab_table_2 : Optional[pd.DataFrame] = None, nproc: int = 1
    ):
        self.species_ab_table = species_ab_table
        self.species_ab_table_2 = species_ab_table_2
        self.nproc = nproc

    def search_contamination(self):
        if not self.species_ab_table_2 is None:
            all_samples = self.species_ab_table.columns
            all_samples_2 = self.species_ab_table_2.columns
            all_sample_pairs = product(all_samples, all_samples_2)
            num_sample_pairs = len(all_samples) * len(all_samples_2)
            self.species_ab_table = self.species_ab_table.join(self.species_ab_table_2)
        else:
            all_samples = self.species_ab_table.columns
            all_sample_pairs = product(all_samples, repeat=2)
            num_sample_pairs = len(all_samples) ** 2

        rf_classifier = RandomForestModel.load()
        worker = ContaminationSearcherWorker(self.species_ab_table, rf_classifier)

        all_conta_events = []

        with Pool(processes=self.nproc) as pool:
            all_tasks = pool.imap_unordered(
                worker.classify_sample_pair, all_sample_pairs, chunksize=self.DEFAULT_CHUNKSIZE
            )
            pbar = partial(
                tqdm.tqdm,
                total=num_sample_pairs,
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} sample pairs inspected",
            )
            for conta_event in pbar(all_tasks):
                if conta_event.probability >= ContaminationSearcherWorker.PROBABILITY_CUTOFF:
                    all_conta_events.append(conta_event)

        return all_conta_events
